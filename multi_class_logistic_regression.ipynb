{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshugaur17/machine-learning-algos/blob/main/multi_class_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oF6bcFSa_q7K"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiFigg0LSuwY",
        "outputId": "0a642f02-daf2-4c15-9eb1-58a85c664808"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "    X = np.array([[-2, 4], [4, 1], [1, 6], [2, 4], [6, 2]])\n",
        "    y = np.array([0, 0, 1, 1, 1])\n",
        "    np.shape(y.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "f_PGc1h1Qiy7"
      },
      "outputs": [],
      "source": [
        "class LRClassifier:\n",
        "    def __init__(self, lam):\n",
        "      self.regularizer=lam\n",
        "      self.theta=None\n",
        "      self.b=None\n",
        "\n",
        "    def loss(self, h, y):\n",
        "      n=y.shape[0]\n",
        "      squared_theta_sum=np.dot(self.theta,self.theta.T)\n",
        "      average_squared_theta_sum=(self.regularizer*squared_theta_sum)/(2*n)\n",
        "      log_loss=(np.dot(y,np.log(h).T)+np.dot(1-y,np.log(1-h).T))/(2*n)\n",
        "      return average_squared_theta_sum-log_loss\n",
        "\n",
        "    def fit(self, X, y, n_iters = 100, alpha = 1):\n",
        "      n,k=X.shape\n",
        "      loss_list=[]\n",
        "      self.theta=np.zeros((k,))\n",
        "      self.b=0\n",
        "      h=self.decision_function(X)\n",
        "      loss_list.append(self.loss(h,y))\n",
        "      for i in range(n_iters):\n",
        "        h=self.decision_function(X)\n",
        "        error=h-y\n",
        "        error_multiplied_by_x=np.dot(X.T,error)+np.multiply(2*self.regularizer,self.theta)\n",
        "        self.b=self.b-(alpha/(2*n))*(np.sum(error,axis=0))\n",
        "        self.theta=self.theta-np.multiply((alpha/(2*n)),error_multiplied_by_x)\n",
        "        h=self.decision_function(X)\n",
        "        loss_list.append(self.loss(h,y))\n",
        "      return loss_list\n",
        "\n",
        "    def get_params(self):\n",
        "      return self.theta,self.b\n",
        "\n",
        "    def sigmoid(self,x):\n",
        "      return 1.0/(1.0+np.exp(-x))\n",
        "\n",
        "    def decision_function(self, X):\n",
        "      fx=np.dot(X,self.theta.T)+self.b\n",
        "      h=self.sigmoid(fx)\n",
        "      return h\n",
        "\n",
        "    def predict(self, X):\n",
        "      h=self.decision_function(X)\n",
        "      return np.where(h>=0.5,1,0)\n",
        "\n",
        "def binary_lr_classifier(lam = 1e-4):\n",
        "    return LRClassifier(lam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhdi3Uy2QkAt",
        "outputId": "bea4149f-ecf1-432d-9d8a-014610b3481c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5 0.5 0.5 0.5 0.5]\n",
            "[0.3465735902799726]\n",
            "[0.03362681 0.07305424 0.99943041 0.95854417 0.97553659]\n",
            "All tests passed!\n"
          ]
        }
      ],
      "source": [
        "def test_binary_lr_classifier():\n",
        "    X = np.array([[-2, 4], [4, 1], [1, 6], [2, 4], [6, 2]])\n",
        "    y = np.array([0, 0, 1, 1, 1])\n",
        "    lr = binary_lr_classifier(lam = 1e-4)\n",
        "\n",
        "    # before gradient descent\n",
        "    losses = lr.fit(X, y, n_iters = 0)\n",
        "    theta, b = lr.get_params()\n",
        "    print(losses)\n",
        "    assert np.allclose(theta, [0, 0])\n",
        "    assert b == 0\n",
        "\n",
        "    # 1000 iterations\n",
        "    losses = lr.fit(X, y, n_iters = 1000)\n",
        "    theta, b = lr.get_params()\n",
        "    assert np.allclose(theta, [1.62475335, 2.97699553])\n",
        "    assert np.allclose(b, -12.016701793625622)\n",
        "    assert np.allclose(losses[-1], 0.0178892651602277)\n",
        "    assert np.allclose(lr.decision_function(X), [0.0336268115487116, 0.07305423924580728, 0.9994304104089492, 0.9585441655688948, 0.9755365947084815])\n",
        "    assert list(lr.predict(X)) == [0, 0, 1, 1, 1]\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "\n",
        "test_binary_lr_classifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "gUtz3blxYIT8"
      },
      "outputs": [],
      "source": [
        "class MultiClassLRClassifier:\n",
        "    def __init__(self, lam):\n",
        "      self.regularizer=lam\n",
        "      self.theta=None\n",
        "      self.b=None\n",
        "\n",
        "    def generate_label_matrix(self,Y,k):\n",
        "      n=Y.shape[0]\n",
        "      y=np.zeros((n,k))\n",
        "      for i in range(n):\n",
        "        y[i,Y[i]]=1\n",
        "      return y\n",
        "\n",
        "    def loss(self, h, y):\n",
        "      n,k=h.shape\n",
        "      squared_theta_sum=(self.regularizer)*(np.sum(np.square(self.theta)))\n",
        "      cost=squared_theta_sum-np.sum(y*np.log(h))\n",
        "      return cost/(2*n)\n",
        "\n",
        "    def fit(self, X, Y, n_iters = 100, alpha = 1):\n",
        "\n",
        "      classes_count=Y.max()+1\n",
        "      k=classes_count\n",
        "      n,d=X.shape\n",
        "      self.theta=np.zeros((d,k))\n",
        "      self.b=np.zeros((k,))\n",
        "      lr = binary_lr_classifier(lam = 1e-4)\n",
        "      y=self.generate_label_matrix(Y,k)\n",
        "      for i in range(k):\n",
        "        lr.fit(X,y.T[i],n_iters)\n",
        "        self.theta[:,i],self.b[i]=lr.get_params()\n",
        "      return self.loss(self.decision_function(X),y)\n",
        "\n",
        "\n",
        "    def get_params(self):\n",
        "      return self.theta,self.b\n",
        "\n",
        "    def decision_function(self, X):\n",
        "      fx=np.exp(np.dot(X,self.theta)+self.b)\n",
        "      hx=fx/(np.sum(fx,axis=1).reshape(-1,1))\n",
        "      return hx\n",
        "\n",
        "    def predict(self, X):\n",
        "      h=self.decision_function(X)\n",
        "      return np.argmax(h,axis=1)\n",
        "\n",
        "# do not modify this function\n",
        "def multiclass_lr_classifier(lam = 1e-4):\n",
        "    return MultiClassLRClassifier(lam)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_multiclass_lr_classifier():\n",
        "    X = np.array([\n",
        "        [1, 6], [1, 7], [2, 5], [2, 8],\n",
        "        [4, 2], [4, 3], [5, 1], [5, 2],\n",
        "        [5, 3], [6, 1], [6, 2], [9, 4],\n",
        "        [9, 7], [10, 5], [10, 6], [11, 6],\n",
        "        [5, 9], [5, 10], [5, 11], [6, 9],\n",
        "        [6, 10], [7, 10], [8, 11]\n",
        "    ])\n",
        "    y = np.array([\n",
        "        0, 0, 0, 0,\n",
        "        1, 1, 1, 1, 1, 1, 1,\n",
        "        2, 2, 2, 2, 2,\n",
        "        3, 3, 3, 3, 3, 3, 3\n",
        "    ])\n",
        "    multi_lr = multiclass_lr_classifier(lam = 1e-4)\n",
        "\n",
        "    # before gradient descent\n",
        "    final_loss = multi_lr.fit(X, y, n_iters = 0)\n",
        "    thetas, bs = multi_lr.get_params()\n",
        "    assert np.allclose(thetas, np.zeros((2, 4)))\n",
        "    assert np.allclose(bs, np.zeros(4))\n",
        "    assert np.allclose(final_loss, 0.6931471805599453)\n",
        "    assert np.allclose(multi_lr.decision_function(X), np.full((len(y), 4), 0.25))\n",
        "    assert list(multi_lr.predict(X)) == [0] * len(y)\n",
        "\n",
        "    # gradient descent 1 iter\n",
        "    final_loss = multi_lr.fit(X, y, n_iters = 1)\n",
        "    thetas, bs = multi_lr.get_params()\n",
        "    assert np.allclose(thetas, np.array(\n",
        "        [[-1.3043478260869565, -0.6739130434782609, -0.3695652173913043, -0.5217391304347826],\n",
        "         [-0.9347826086956521, -1.1956521739130435, -0.8913043478260869, 0.021739130434782608]]\n",
        "    ))\n",
        "    assert np.allclose(bs, [-0.16304347826086957, -0.09782608695652174, -0.14130434782608695, -0.09782608695652174])\n",
        "    assert np.allclose(final_loss, 1.5948661586516544)\n",
        "    assert np.allclose(multi_lr.decision_function(X), np.loadtxt(\"/content/drive/MyDrive/ApNotebook/machine_learning_v2_2/local_test_refs/multi_lr_decision_function_1.npy\"))\n",
        "    assert list(multi_lr.predict(X)) == [3] * len(y)\n",
        "\n",
        "    # gradient descent 2 iter\n",
        "    final_loss = multi_lr.fit(X, y, n_iters = 2)\n",
        "    thetas, bs = multi_lr.get_params()\n",
        "    assert np.allclose(thetas, np.array(\n",
        "        [[-1.1741525763887666, 0.08405329650269378, 0.6749300069596299, 0.250023946810188],\n",
        "         [-0.3698696640278152, -0.8923347376289046, -0.2904085511104315, 1.252575005389721]]\n",
        "    ))\n",
        "    assert np.allclose(bs, [-0.07616801209977848, 0.05374654543619424, -0.03683221319180832, 0.006708777994691106])\n",
        "    assert np.allclose(final_loss, 2.4507247738274804)\n",
        "    assert np.allclose(multi_lr.decision_function(X), np.loadtxt(\"/content/drive/MyDrive/ApNotebook/machine_learning_v2_2/local_test_refs/multi_lr_decision_function_2.npy\"))\n",
        "    assert list(multi_lr.predict(X)) == [3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
        "\n",
        "    # gradient descent 1000 iter\n",
        "    final_loss = multi_lr.fit(X, y, n_iters = 1000)\n",
        "    thetas, bs = multi_lr.get_params()\n",
        "    assert np.allclose(thetas, np.array(\n",
        "        [[-4.43691485302322, -0.15895242949854863, 1.8314459978612432, 0.11428400803141586],\n",
        "         [1.4462434773266433, -2.243038284524103, -0.4123296983423064, 1.8358466248685217]]\n",
        "    ))\n",
        "    assert np.allclose(bs, [3.3982221320824473, 8.9389563873553, -12.268402031207522, -15.67416835171075])\n",
        "    assert np.allclose(final_loss, 0.0020306591987543157)\n",
        "    assert np.allclose(multi_lr.decision_function(X), np.loadtxt(\"/content/drive/MyDrive/ApNotebook/machine_learning_v2_2/local_test_refs/multi_lr_decision_function_1000.npy\"))\n",
        "    assert list(multi_lr.predict(X)) == list(y)\n",
        "\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "test_multiclass_lr_classifier()"
      ],
      "metadata": {
        "id": "0zJPpDGXmt7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([\n",
        "        [1, 6], [1, 7], [2, 5], [2, 8],\n",
        "        [4, 2], [4, 3], [5, 1], [5, 2],\n",
        "        [5, 3], [6, 1], [6, 2], [9, 4],\n",
        "        [9, 7], [10, 5], [10, 6], [11, 6],\n",
        "        [5, 9], [5, 10], [5, 11], [6, 9],\n",
        "        [6, 10], [7, 10], [8, 11]\n",
        "    ])\n",
        "Y = np.array([\n",
        "        0, 0, 0, 0,\n",
        "        1, 1, 1, 1, 1, 1, 1,\n",
        "        2, 2, 2, 2, 2,\n",
        "        3, 3, 3, 3, 3, 3, 3\n",
        "    ])"
      ],
      "metadata": {
        "id": "0wPATHEW0748"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "      classes_count=Y.max()+1\n",
        "      k=classes_count\n",
        "      n,d=X.shape"
      ],
      "metadata": {
        "id": "py4AZT7aoJdK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta=np.zeros((d,k))\n",
        "b=np.zeros((k,))"
      ],
      "metadata": {
        "id": "VXMY_0hGoPzX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7OjF6GooZ4H",
        "outputId": "2cae01d8-7c38-41a9-eb80-8d17e59d723b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F23cyFzpoJ8",
        "outputId": "feeaa8e4-2386-4658-d39f-5d2f46f8420f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=np.exp(np.dot(X,theta)+b)\n",
        "res=res/np.sum(res,axis=1).reshape(-1,1)\n",
        "res\n",
        "\n",
        "np.argmax(res,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1GZ9-Avoep1",
        "outputId": "befa939a-d270-4b0c-c531-aa995469414e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.loadtxt(\"/content/drive/MyDrive/ApNotebook/machine_learning_v2_2/local_test_refs/multi_lr_decision_function_1000.npy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w3IforaoxaU",
        "outputId": "f2ee172f-27b9-43c2-9c84-3f69cd87acc8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99990410e-01, 4.47500324e-06, 1.18952478e-09, 5.11372566e-06],\n",
              "       [9.99992338e-01, 1.11830297e-07, 1.85441211e-10, 7.54989236e-06],\n",
              "       [9.86930825e-01, 1.27413199e-02, 3.97325990e-06, 3.23881661e-04],\n",
              "       [9.98944793e-01, 2.01263517e-07, 1.52369318e-08, 1.05499068e-03],\n",
              "       [2.32566492e-07, 9.99930762e-01, 6.87924349e-05, 2.12892518e-07],\n",
              "       [9.30285119e-06, 9.99549140e-01, 4.28984439e-04, 1.25727948e-05],\n",
              "       [8.06142791e-11, 9.99919292e-01, 8.07027097e-05, 4.73569021e-09],\n",
              "       [3.22450465e-09, 9.99496482e-01, 5.03235275e-04, 2.79664161e-07],\n",
              "       [1.28690738e-07, 9.96852362e-01, 3.13103041e-03, 1.64787246e-05],\n",
              "       [1.11762241e-12, 9.99409676e-01, 5.90317656e-04, 6.22052392e-09],\n",
              "       [4.45850005e-11, 9.96328405e-01, 3.67122813e-03, 3.66372725e-07],\n",
              "       [3.34263719e-15, 1.74791366e-02, 9.82469941e-01, 5.09225622e-05],\n",
              "       [8.60067764e-13, 7.01874190e-05, 9.57763933e-01, 4.21658800e-02],\n",
              "       [4.13443382e-17, 3.89500073e-04, 9.99522395e-01, 8.81049076e-05],\n",
              "       [2.65095338e-16, 6.24106747e-05, 9.99103546e-01, 8.34043386e-04],\n",
              "       [5.02815035e-19, 8.53415483e-06, 9.99841582e-01, 1.49884029e-04],\n",
              "       [7.53297387e-04, 1.42115597e-06, 2.63086163e-04, 9.98982195e-01],\n",
              "       [5.10472530e-04, 2.40665007e-08, 2.77930270e-05, 9.99461710e-01],\n",
              "       [3.45821690e-04, 4.07434770e-10, 2.93526710e-06, 9.99651243e-01],\n",
              "       [7.94708387e-06, 1.08088267e-06, 1.46438028e-03, 9.98526592e-01],\n",
              "       [5.38984242e-06, 1.83194366e-08, 1.54829627e-04, 9.99839762e-01],\n",
              "       [5.68474168e-08, 1.39297157e-08, 8.61595185e-04, 9.99138334e-01],\n",
              "       [4.06538711e-10, 1.79470961e-10, 5.06804997e-04, 9.99493194e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dEcQS6nh00rJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KxD0Z45O33_CyrxD2QuCbLkvJz0BFDmN",
      "authorship_tag": "ABX9TyMLgQ55s2MTDwtbraVULCLH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
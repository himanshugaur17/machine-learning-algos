{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshugaur17/machine-learning-algos/blob/main/logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oF6bcFSa_q7K"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiFigg0LSuwY",
        "outputId": "0a642f02-daf2-4c15-9eb1-58a85c664808"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "    X = np.array([[-2, 4], [4, 1], [1, 6], [2, 4], [6, 2]])\n",
        "    y = np.array([0, 0, 1, 1, 1])\n",
        "    np.shape(y.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "f_PGc1h1Qiy7"
      },
      "outputs": [],
      "source": [
        "class LRClassifier:\n",
        "    def __init__(self, lam):\n",
        "      self.regularizer=lam\n",
        "      self.theta=None\n",
        "      self.b=None\n",
        "\n",
        "    def loss(self, h, y):\n",
        "      n=y.shape[0]\n",
        "      squared_theta_sum=np.dot(self.theta,self.theta.T)\n",
        "      average_squared_theta_sum=(self.regularizer*squared_theta_sum)/(2*n)\n",
        "      log_loss=(np.dot(y,np.log(h).T)+np.dot(1-y,np.log(1-h).T))/(2*n)\n",
        "      return average_squared_theta_sum-log_loss\n",
        "\n",
        "    def fit(self, X, y, n_iters = 100, alpha = 1):\n",
        "      n,k=X.shape\n",
        "      loss_list=[]\n",
        "      self.theta=np.zeros((k,))\n",
        "      self.b=0\n",
        "      h=self.decision_function(X)\n",
        "      loss_list.append(self.loss(h,y))\n",
        "      for i in range(n_iters):\n",
        "        h=self.decision_function(X)\n",
        "        error=h-y\n",
        "        error_multiplied_by_x=np.dot(X.T,error)+np.multiply(2*self.regularizer,self.theta)\n",
        "        self.b=self.b-(alpha/(2*n))*(np.sum(error,axis=0))\n",
        "        self.theta=self.theta-np.multiply((alpha/(2*n)),error_multiplied_by_x)\n",
        "        h=self.decision_function(X)\n",
        "        loss_list.append(self.loss(h,y))\n",
        "      return loss_list\n",
        "\n",
        "    def get_params(self):\n",
        "      return self.theta,self.b\n",
        "\n",
        "    def sigmoid(self,x):\n",
        "      return 1.0/(1.0+np.exp(-x))\n",
        "\n",
        "    def decision_function(self, X):\n",
        "      fx=np.dot(X,self.theta.T)+self.b\n",
        "      h=self.sigmoid(fx)\n",
        "      return h\n",
        "\n",
        "    def predict(self, X):\n",
        "      h=self.decision_function(X)\n",
        "      return np.where(h>=0.5,1,0)\n",
        "\n",
        "def binary_lr_classifier(lam = 1e-4):\n",
        "    return LRClassifier(lam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhdi3Uy2QkAt",
        "outputId": "4655fdf4-3aa3-44e6-8212-5999b5e770bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3465735902799726]\n"
          ]
        }
      ],
      "source": [
        "def test_binary_lr_classifier():\n",
        "    X = np.array([[-2, 4], [4, 1], [1, 6], [2, 4], [6, 2]])\n",
        "    y = np.array([0, 0, 1, 1, 1])\n",
        "    lr = binary_lr_classifier(lam = 1e-4)\n",
        "\n",
        "    # before gradient descent\n",
        "    losses = lr.fit(X, y, n_iters = 0)\n",
        "    theta, b = lr.get_params()\n",
        "    print(losses)\n",
        "    assert np.allclose(theta, [0, 0])\n",
        "    assert b == 0\n",
        "    assert np.allclose(losses[-1], 0.34657359027997264)\n",
        "    assert np.allclose(lr.decision_function(X), [0.5] * 5)\n",
        "    assert list(lr.predict(X)) == [1] * len(y)\n",
        "\n",
        "    # 1000 iterations\n",
        "    losses = lr.fit(X, y, n_iters = 1000)\n",
        "    theta, b = lr.get_params()\n",
        "    assert np.allclose(theta, [1.62475335, 2.97699553])\n",
        "    assert np.allclose(b, -12.016701793625622)\n",
        "    assert np.allclose(losses[-1], 0.0178892651602277)\n",
        "    assert np.allclose(lr.decision_function(X), [0.0336268115487116, 0.07305423924580728, 0.9994304104089492, 0.9585441655688948, 0.9755365947084815])\n",
        "    assert list(lr.predict(X)) == [0, 0, 1, 1, 1]\n",
        "\n",
        "\n",
        "test_binary_lr_classifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUtz3blxYIT8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIZfu9cn6LOJ6erNlcxB5Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}